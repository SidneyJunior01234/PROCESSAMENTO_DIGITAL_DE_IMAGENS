:numbered:
:author: Sidney Alves dos Santos Junior
:icons:
:experimental:
:stem:
:imagesdir: ../figs
:toc: left
:doctype: book
:source-highlighter: rouge
:caution-caption: Cuidado
:important-caption: Importante
:note-caption: Nota
:tip-caption: Dica
:warning-caption: Aviso
:appendix-caption: Apêndice
:example-caption: Exemplo
:figure-caption: Figura
:listing-caption: Listagem
:table-caption: Tabela
:toc-title: Sumário
:preface-title: Prefácio
:version-label: Versão
:last-update-label: Última atualização

== Quantização vetorial com k-means ==

Para essa prática, será utilizado um algoritmo de quantização que é uma técnica usada para mapear dados de um conjunto grande em um conjunto menor. Será utilizado o K-means que é um dos mais populares por sua simplicidade e performance.

O exercício está disponível em link:https://agostinhobritojr.github.io/tutorial/pdi/kmeans.html[Capítulo 20. Quantização vetorial com k-means].

=== Redução e Comparação de Cores com K-Means ===

O programa fornecido na página do exercício opera sobre a imagem reduzindo a quantidade de cores presente na mesma, com isso são necessários alguns parâmetros que serão armazenados em variáveis.

.Variáveis Essenciais
[source,python,subs="+quotes"]
----
numero_de_clusters = 8
criterio_de_parada = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
n_rodadas = 10
----

Essas variáveis são responsáveis pela inicialização do K-means e pela quantidade de execuções que serão realizadas.

.Conversão das Imagens
[source,python,subs="+quotes"]
----
dados = imagem.reshape((-1,3))
dados = np.float32(dados)
----

Nessa conversão, realizamos o reshape para que os dados deixem de ser altura x largura, para serem altura x largura x colunas (3).

Apósa isso é utilizado um laço for para iterar na quantidade de repetições desejadas para a geração das novas imagens. Cada iteração conta com a inicialização do K-means onde os centrides são selecionados aleatoriamente e após isso o reshape é feito para que os dados retornem a serem imagens e são armazenados em uma lista.

.Aplicação do K-means
[source,python,subs="+quotes"]
----
resultados = []

for i in range(n_rodadas):
    ret, rotulos, centros = cv2.kmeans(dados, numero_de_clusters, None, criterio_de_parada, n_rodadas, cv2.KMEANS_RANDOM_CENTERS)

    # Converter os rótulos para a forma original da imagem
    centros = np.uint8(centros)
    resultado = centros[rotulos.flatten()]
    resultado_final = resultado.reshape((imagem.shape))
    resultados.append(resultado_final)
----

Para observar as imagens, foi usado o subplots do matplotlib que exibe as imagens em um grid. 

.Exibição das imagens
[source,python,subs="+quotes"]
----
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
for i, ax in enumerate(axes.flat):
    ax.imshow(resultados[i])
    ax.set_title(f"Rodada {i+1}")
plt.tight_layout()
plt.show()
----

Com isso ao aplicar o algoritmo modificado na imagem da lena.png teremos.

.Imagem Original
image:lena.png[imagem 01]

.Resultado
image:lena_comp.png[imagem 02]

É possível observar que algumas das imagens diferem das outras, isso se deve a inicialização dos clusters e a suas convergencias.
A inicialização aleatória dos centros no K-means introduz uma fonte de variabilidade nos resultados, que são notáveis no resultado devido às diferenças de cores finais.

Para executar o programa utilize o comando:
.Exemplo de comando de execução
----
python3 nome_arquivo.py caminho_imagem
----
